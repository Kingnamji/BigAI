{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_NNTrain",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay70F-FR2dHt"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DRDCiw51wsl"
      },
      "source": [
        "# 손실 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ3Fu-Hq1x04",
        "outputId": "97a25176-05b3-4ea7-ab32-905f18135ac7"
      },
      "source": [
        "# 오차제곱합\n",
        "def sum_squares_error(y, t): \n",
        "  return 0.5 * np.sum((y-t)**2)\n",
        "\n",
        "# 원 핫 인코딩\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # 정답 2\n",
        "\n",
        "# 신경망의 출력 2인 경우\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n",
        "# 신경망의 출력이 7인 경우\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ZKxSga4qPa",
        "outputId": "1cc463da-b28e-4d88-b924-3fd761bc26eb"
      },
      "source": [
        "# 크로스 엔트로피\n",
        "def cross_entropy_error(y, t):\n",
        "  delta = 1e-7 # log에 0 이 입력되는 사태 방지\n",
        "  return -np.sum(t * np.log(y + delta)) \n",
        "\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtS2VFLS496V",
        "outputId": "9a0e1df5-3d93-40b4-fab5-ec325a31b685"
      },
      "source": [
        "path = '/content/drive/MyDrive/deep-learning-from-scratch-master'\n",
        "os.chdir(path)\n",
        "sys.path.append(os.chdir)\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape, '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hx0Fer5SfV",
        "outputId": "f75abef6-d962-4a56-d822-d70bddd64e3f"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "\n",
        "#x_batch = x_train[batch_mask]\n",
        "#t_batch = t_train[batch_mask]\n",
        "print(batch_mask)\n",
        "print(np.random.choice(60000, 10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[52950 16350 22210 19322 26941 10697 44587 30966 34557 31363]\n",
            "[ 1686 26428  9950 24176 53650 54113 14592 11697   324 17053]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}